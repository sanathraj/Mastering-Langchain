{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b62df688",
      "metadata": {
        "id": "b62df688"
      },
      "source": [
        "# Chapter 9: LangChain Framework Integrations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup"
      ],
      "metadata": {
        "id": "Glzrsuoh83IT"
      },
      "id": "Glzrsuoh83IT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b49352f2",
      "metadata": {
        "tags": [
          "install"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b49352f2",
        "outputId": "dcaa6037-8f80-440b-99b1-540f49887017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Library langchain version: 0.3.23\n",
            "Library langchain_community not found. Installing...\n",
            "Library huggingface_hub version: 0.30.2\n",
            "Library langchain_openai not found. Installing...\n"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "libraries = [\"langchain\", \"langchain_community\", \"huggingface_hub\", \"langchain_openai\"]\n",
        "\n",
        "for library in libraries:\n",
        "    try:\n",
        "        # Try to import the library\n",
        "        module = importlib.import_module(library)\n",
        "        print(f\"Library {library} version: {module.__version__}\")\n",
        "    except ImportError:\n",
        "        # If library is not installed, attempt to install it\n",
        "        print(f\"Library {library} not found. Installing...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", library])\n",
        "        # After installing, import again and print the version\n",
        "        module = importlib.import_module(library)\n",
        "        # print(f\"Library {library} version after installation: {module.__version__}\")\n",
        "    except AttributeError:\n",
        "        # If library doesn't have __version__ attribute\n",
        "        print(f\"Library {library} does not have a __version__ attribute.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "GxAq4g3NqLTf"
      },
      "id": "GxAq4g3NqLTf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UJ-I3tnuqLq5"
      },
      "id": "UJ-I3tnuqLq5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connect to HuggingFace LLM**"
      ],
      "metadata": {
        "id": "-hXq5IplqLvZ"
      },
      "id": "-hXq5IplqLvZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load LLaMA 4 model from Hugging Face Hub (make sure it's a chat-compatible LLaMA4 model)\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",  # Adjust if you're using LLaMA 4 when it's available\n",
        "    model_kwargs={\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"top_p\": 0.9,\n",
        "        \"repetition_penalty\": 1.1\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "lUx381QBptVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5884b9ec-5264-4215-93bf-4d69e56f1f4c"
      },
      "id": "lUx381QBptVb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-16d6ed11a576>:3: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
            "  llm = HuggingFaceHub(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Azure OpenAI LLM"
      ],
      "metadata": {
        "id": "Cvi-RoLvb360"
      },
      "id": "Cvi-RoLvb360"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import AzureOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2024-05-01-preview\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get('AZ_OPENAI_KEY')\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] =  \"https://azopenai-demo.openai.azure.com/\"\n",
        "\n",
        "llm = AzureOpenAI(deployment_name=\"dp-gpt-35-turbo-instruct\", model_name=\"gpt-35-turbo-instruct\")\n",
        "embedding_model = AzureOpenAI(deployment_name=\"dp-text-embedding-ada-002\", model_name=\"text-embedding-ada-002\")"
      ],
      "metadata": {
        "id": "6Zkssiikb6cF"
      },
      "id": "6Zkssiikb6cF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with External APIs"
      ],
      "metadata": {
        "id": "XRb0Zu0I9EUL"
      },
      "id": "XRb0Zu0I9EUL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go to https://home.openweathermap.org/api_keys and create a free account to generate a free key"
      ],
      "metadata": {
        "id": "njnWev4396cE"
      },
      "id": "njnWev4396cE"
    },
    {
      "cell_type": "code",
      "source": [
        "openWeatherAPI_key = \"<openWeatherAPI key>\""
      ],
      "metadata": {
        "id": "gAhNkOMG-GFQ"
      },
      "id": "gAhNkOMG-GFQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import BaseTool\n",
        "import requests\n",
        "\n",
        "class WeatherTool(BaseTool):\n",
        "    name: str = \"weather_tool\"\n",
        "    description: str = \"Fetches weather information for a given city.\"\n",
        "\n",
        "    def _run(self, city: str) -> str:\n",
        "        api_key = openWeatherAPI_key  # <-- make sure to define your API key properly\n",
        "        url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric\"\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "        if response.status_code == 200:\n",
        "            return f\"The weather in {city} is {data['weather'][0]['description']} with a temperature of {data['main']['temp']} °C.\"\n",
        "        else:\n",
        "            return f\"Failed to fetch weather data: {data.get('message', 'Unknown error')}\"\n",
        "\n",
        "    async def _arun(self, city: str) -> str:\n",
        "        raise NotImplementedError(\"Async not implemented yet.\")\n"
      ],
      "metadata": {
        "id": "DsV7-Q6l9FGN"
      },
      "id": "DsV7-Q6l9FGN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_tool = WeatherTool()\n",
        "city = \"London\"\n",
        "result = weather_tool._run(city)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uoo6R4_4-MDD",
        "outputId": "9e79cde5-8a13-4ee1-d33c-21669bf68deb"
      },
      "id": "Uoo6R4_4-MDD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in London is overcast clouds with a temperature of 7.75 °C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the Tool in an Agent"
      ],
      "metadata": {
        "id": "9a3MhfF__TkD"
      },
      "id": "9a3MhfF__TkD"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "weather_tool = WeatherTool()\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=[weather_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")\n",
        "\n",
        "response = agent.invoke(\"What's the weather like in Dublin today?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGeYo9mm_UHz",
        "outputId": "edc44757-d521-4844-e43e-af0d2ddf9769"
      },
      "id": "rGeYo9mm_UHz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-e9672950623b>:6: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n",
            "<ipython-input-12-e9672950623b>:12: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = agent.run(\"What's the weather like in Dublin today?\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am unable to answer the original question as I am unable to fetch the weather for Dublin.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis with a PyTorch Model\n"
      ],
      "metadata": {
        "id": "90VIq9B8Kkfz"
      },
      "id": "90VIq9B8Kkfz"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from langchain.tools import BaseTool\n",
        "from typing import Optional\n",
        "from pydantic import Field, model_validator\n",
        "\n",
        "class SentimentAnalysisTool(BaseTool):\n",
        "    name: str = \"sentiment_analysis\"\n",
        "    description: str = \"Classifies the sentiment of a given text.\"\n",
        "    model_name: Optional[str] = Field(default=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "    # These are not Pydantic fields, they will be set after initialization\n",
        "    tokenizer: BertTokenizer = None\n",
        "    model: BertForSequenceClassification = None\n",
        "\n",
        "    @model_validator(mode=\"after\")\n",
        "    def load_model(self) -> \"SentimentAnalysisTool\":\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n",
        "        self.model = BertForSequenceClassification.from_pretrained(self.model_name)\n",
        "        return self\n",
        "\n",
        "    def _run(self, text: str) -> str:\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "        outputs = self.model(**inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "        sentiment_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "        if sentiment_class <= 1:\n",
        "            return \"Negative\"\n",
        "        elif sentiment_class == 2:\n",
        "            return \"Neutral\"\n",
        "        else:\n",
        "            return \"Positive\"\n",
        "\n",
        "    async def _arun(self, text: str) -> str:\n",
        "        raise NotImplementedError(\"Async not implemented yet.\")"
      ],
      "metadata": {
        "id": "tK1Kx5xCKlHi"
      },
      "id": "tK1Kx5xCKlHi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the tool\n",
        "tool = SentimentAnalysisTool()\n",
        "\n",
        "# Run sentiment analysis\n",
        "text = \"I love this product, it's amazing!\"\n",
        "result = tool._run(text)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "88dc7ca1960249088895be49b06493c3",
            "a83f0d925f6744178e5328766530d79b",
            "72b8c15a77434c32975c4be3d9054981",
            "b72f3486c0b8401fa2563cfc02928a7e",
            "9a288a7082a54b4fa1f90fcd25590e71",
            "2d05dd9e33a946e8927b05bdc3375932",
            "3e88ee381c9841f5b39ac6a3acd9459a",
            "8ae2cf9bccdd4bad99d0fdc212349d16",
            "4f9504e6cffc45e092f619594e7c04b8",
            "f313120d190f4502947b8e3bfff6f903",
            "78b2bfaeab5b456189ce3209ed9fd719"
          ]
        },
        "id": "dJ7b19xNKsbC",
        "outputId": "bf147092-2fc5-4ed1-f9c2-8256bce489ac"
      },
      "id": "dJ7b19xNKsbC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88dc7ca1960249088895be49b06493c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Router Example Code"
      ],
      "metadata": {
        "id": "SZJqBUHUMcQ2"
      },
      "id": "SZJqBUHUMcQ2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from langchain.llms import HuggingFaceHub, AzureOpenAI\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain.tools import Tool\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.schema import SystemMessage\n",
        "\n",
        "# Reuse components from your uploaded file\n",
        "# llm is already created: (AzureOpenAI or HuggingFaceHub)\n",
        "\n",
        "# Reuse SentimentAnalysisTool\n",
        "# Make sure you have this class already imported from your code:\n",
        "# class SentimentAnalysisTool(BaseTool): ...\n",
        "\n",
        "sentiment_tool = SentimentAnalysisTool()\n",
        "\n",
        "# Create a lightweight LLM reasoning function\n",
        "def llm_reasoning_function(query: str) -> str:\n",
        "    \"\"\"Handles general reasoning queries via LLM.\"\"\"\n",
        "    return llm.invoke(query)\n",
        "\n",
        "# Router function\n",
        "def router(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Decide whether to use SentimentAnalysisTool or LLM based on task.\n",
        "    If query mentions 'sentiment' or 'classify', route to SentimentAnalysisTool.\n",
        "    Else, route to LLM.\n",
        "    \"\"\"\n",
        "    keywords = [\"sentiment\", \"classify\", \"classification\"]\n",
        "    if any(keyword in query.lower() for keyword in keywords):\n",
        "        return \"sentiment_analysis\"\n",
        "    else:\n",
        "        return \"llm_reasoning\"\n",
        "\n",
        "# Set up tools\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        name=\"sentiment_analysis\",\n",
        "        description=\"Classifies text sentiment using a custom PyTorch model.\",\n",
        "        func=sentiment_tool._run,\n",
        "    ),\n",
        "    Tool.from_function(\n",
        "        name=\"llm_reasoning\",\n",
        "        description=\"Handles general reasoning queries with an LLM.\",\n",
        "        func=llm_reasoning_function,\n",
        "    )\n",
        "]\n",
        "\n",
        "# Custom agent prompt\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessage(content=\"You are a hybrid agent that routes tasks either to a sentiment classifier or an LLM.\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "# Create an agent\n",
        "agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=prompt)\n",
        "\n",
        "# Create an executor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "# Hybrid Execution function\n",
        "def hybrid_agent_executor(user_query: str):\n",
        "    selected_tool_name = router(user_query)\n",
        "    for tool in tools:\n",
        "        if tool.name == selected_tool_name:\n",
        "            response = tool.invoke(user_query)\n",
        "            break\n",
        "    return response\n",
        "\n",
        "# Example Usage\n",
        "query1 = \"Can you classify the sentiment of this text: 'I hate rainy days.'?\"\n",
        "query2 = \"What's the capital of France?\"\n",
        "query3 = \"What's the weather of France today?\"\n",
        "\n",
        "print(\"Query 1 Result:\", hybrid_agent_executor(query1))\n",
        "print(\"Query 2 Result:\", hybrid_agent_executor(query2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSYu62d1N3mq",
        "outputId": "c367a8be-e76b-42b5-adfd-2cd3ed2f324c"
      },
      "id": "qSYu62d1N3mq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query 1 Result: Negative\n",
            "Query 2 Result: \n",
            "\n",
            "The capital of France is Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "afUezig7OciY"
      },
      "id": "afUezig7OciY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88dc7ca1960249088895be49b06493c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a83f0d925f6744178e5328766530d79b",
              "IPY_MODEL_72b8c15a77434c32975c4be3d9054981",
              "IPY_MODEL_b72f3486c0b8401fa2563cfc02928a7e"
            ],
            "layout": "IPY_MODEL_9a288a7082a54b4fa1f90fcd25590e71"
          }
        },
        "a83f0d925f6744178e5328766530d79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d05dd9e33a946e8927b05bdc3375932",
            "placeholder": "​",
            "style": "IPY_MODEL_3e88ee381c9841f5b39ac6a3acd9459a",
            "value": "model.safetensors: 100%"
          }
        },
        "72b8c15a77434c32975c4be3d9054981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ae2cf9bccdd4bad99d0fdc212349d16",
            "max": 669464588,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f9504e6cffc45e092f619594e7c04b8",
            "value": 669464588
          }
        },
        "b72f3486c0b8401fa2563cfc02928a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f313120d190f4502947b8e3bfff6f903",
            "placeholder": "​",
            "style": "IPY_MODEL_78b2bfaeab5b456189ce3209ed9fd719",
            "value": " 669M/669M [00:08&lt;00:00, 119MB/s]"
          }
        },
        "9a288a7082a54b4fa1f90fcd25590e71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d05dd9e33a946e8927b05bdc3375932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e88ee381c9841f5b39ac6a3acd9459a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ae2cf9bccdd4bad99d0fdc212349d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f9504e6cffc45e092f619594e7c04b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f313120d190f4502947b8e3bfff6f903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78b2bfaeab5b456189ce3209ed9fd719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}