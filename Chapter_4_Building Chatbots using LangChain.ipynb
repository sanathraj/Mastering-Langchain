{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b62df688",
      "metadata": {
        "id": "b62df688"
      },
      "source": [
        "# Chapter 4: Building Chatbots using LangChain\n",
        "\n",
        "This notebook accompanies Chapter 4 of the LangChain guide, demonstrating practical implementations and setup instructions for building chatbots with LangChain.\n",
        "\n",
        "Ensure you have Python 3.8+ installed before proceeding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b49352f2",
      "metadata": {
        "tags": [
          "install"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b49352f2",
        "outputId": "66bbd69d-9e63-4896-a110-fcb645d1f332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Library langchain version: 0.3.23\n",
            "Library langchain_community version: 0.3.21\n",
            "Library huggingface_hub version: 0.30.1\n",
            "Library langchain_openai does not have a __version__ attribute.\n"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "libraries = [\"langchain\", \"langchain_community\", \"huggingface_hub\", \"langchain_openai\"]\n",
        "\n",
        "for library in libraries:\n",
        "    try:\n",
        "        # Try to import the library\n",
        "        module = importlib.import_module(library)\n",
        "        print(f\"Library {library} version: {module.__version__}\")\n",
        "    except ImportError:\n",
        "        # If library is not installed, attempt to install it\n",
        "        print(f\"Library {library} not found. Installing...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", library])\n",
        "        # After installing, import again and print the version\n",
        "        module = importlib.import_module(library)\n",
        "        # print(f\"Library {library} version after installation: {module.__version__}\")\n",
        "    except AttributeError:\n",
        "        # If library doesn't have __version__ attribute\n",
        "        print(f\"Library {library} does not have a __version__ attribute.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "GxAq4g3NqLTf"
      },
      "id": "GxAq4g3NqLTf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UJ-I3tnuqLq5"
      },
      "id": "UJ-I3tnuqLq5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connect to HuggingFace LLM**"
      ],
      "metadata": {
        "id": "-hXq5IplqLvZ"
      },
      "id": "-hXq5IplqLvZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load LLaMA 4 model from Hugging Face Hub (make sure it's a chat-compatible LLaMA4 model)\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",  # Adjust if you're using LLaMA 4 when it's available\n",
        "    model_kwargs={\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"top_p\": 0.9,\n",
        "        \"repetition_penalty\": 1.1\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "lUx381QBptVb"
      },
      "id": "lUx381QBptVb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Azure OpenAI LLM"
      ],
      "metadata": {
        "id": "Cvi-RoLvb360"
      },
      "id": "Cvi-RoLvb360"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import AzureOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2024-05-01-preview\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get('AZ_OPENAI_KEY')\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] =  \"https://azopenai-demo.openai.azure.com/\"\n",
        "\n",
        "llm = AzureOpenAI(deployment_name=\"dp-gpt-35-turbo-instruct\", model_name=\"gpt-35-turbo-instruct\")\n",
        "embedding_model = AzureOpenAI(deployment_name=\"dp-text-embedding-ada-002\", model_name=\"text-embedding-ada-002\")"
      ],
      "metadata": {
        "id": "6Zkssiikb6cF"
      },
      "id": "6Zkssiikb6cF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3aac70f6",
      "metadata": {
        "id": "3aac70f6"
      },
      "source": [
        "## Context Management Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eefcaf88",
      "metadata": {
        "tags": [
          "example"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eefcaf88",
        "outputId": "6cc4e160-2cce-4840-8591-b32787155b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi, my name is Alice.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Hello Alice, it's nice to meet you. My name is AI, which stands for artificial intelligence. I am a computer program designed to simulate human conversation and assist with various tasks. What can I help you with today? \n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi, my name is Alice.\n",
            "AI:  Hello Alice, it's nice to meet you. My name is AI, which stands for artificial intelligence. I am a computer program designed to simulate human conversation and assist with various tasks. What can I help you with today? \n",
            "Human: Can you help me with my account?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Of course, I'll be happy to help you with your account. Can you please provide me with your account information so I can access it? This will include your username, password, and any other relevant details. I take the security of your account very seriously.\n"
          ]
        }
      ],
      "source": [
        "# Initialize memory\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Create ConversationChain with memory\n",
        "chatbot = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
        "\n",
        "# Simulate a multi-turn conversation\n",
        "print(chatbot.run(\"Hi, my name is Alice.\"))\n",
        "print(chatbot.run(\"Can you help me with my account?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf36b1cd",
      "metadata": {
        "id": "bf36b1cd"
      },
      "source": [
        "## Tool Integration Example (Weather API)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a46df89",
      "metadata": {
        "tags": [
          "example"
        ],
        "id": "1a46df89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798a2a8e-142b-494b-e464-27206b175ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': \"What's the weather in Paris?\", 'output': 'The weather in Paris is sunny and 25°C.'}\n"
          ]
        }
      ],
      "source": [
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "def get_weather(location):\n",
        "    return f\"The weather in {location} is sunny and 25°C.\"\n",
        "\n",
        "weather_tool = Tool(\n",
        "    name=\"Weather\",\n",
        "    func=get_weather,\n",
        "    description=\"Provides weather updates for a given location.\"\n",
        ")\n",
        "\n",
        "# llm = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
        "agent = initialize_agent([weather_tool], llm, agent_type=AgentType.CONVERSATIONAL_REACT_DESCRIPTION)\n",
        "\n",
        "print(agent.invoke(\"What's the weather in Paris?\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aad0777",
      "metadata": {
        "id": "8aad0777"
      },
      "source": [
        "## Multi-Turn Banking Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2c44928",
      "metadata": {
        "tags": [
          "example"
        ],
        "id": "b2c44928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e15e112d-f76a-4300-9d42-e42179d105e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to your banking assistant! Type 'exit' to end.\n",
            "You: how to open bank account?\n",
            "Bot:  To open a bank account, you will need to visit a bank branch or go online to the bank's website. You will need to provide personal information such as your name, address, Social Security number, and a form of identification. The bank may also require a minimum deposit to open the account. Once your account is open, you will receive a debit card and checks to use for your transactions. It's important to carefully read and understand the terms and conditions of the account before opening it. Do you have any specific questions about the process?\n",
            "You: thanks\n",
            "Bot:  You're welcome! Is there anything else I can assist you with?\n",
            "You: exit\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "# Step 2: Configure Memory for Context Maintenance\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Step 3: Create the Conversation Chain\n",
        "banking_bot = ConversationChain(llm=llm, memory=memory)\n",
        "\n",
        "# Step 4: Define User Interactions\n",
        "def banking_chat():\n",
        "    print(\"Welcome to your banking assistant! Type 'exit' to end.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "        response = banking_bot.run(user_input)\n",
        "        print(f\"Bot: {response}\")\n",
        "\n",
        "banking_chat()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "260f1a50",
      "metadata": {
        "id": "260f1a50"
      },
      "source": [
        "## Travel Assistant Query with Tool Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1954c513",
      "metadata": {
        "tags": [
          "example"
        ],
        "id": "1954c513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17562362-6ac6-4fa9-d9ff-7653707299ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best flight to take to Paris would be with AirFrance and the best hotel to stay at near the Eiffel Tower would be Hotel A.\n"
          ]
        }
      ],
      "source": [
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Define mock tools for flights and hotels\n",
        "def find_flights(destination):\n",
        "    return f\"Flights to {destination}: AirFrance, Delta, and Lufthansa.\"\n",
        "\n",
        "def find_hotels(location):\n",
        "    return f\"Hotels near {location}: Hotel A, Hotel B, and Hotel C.\"\n",
        "\n",
        "flight_tool = Tool(\n",
        "    name=\"Flight Finder\",\n",
        "    func=find_flights,\n",
        "    description=\"Finds flights to a specified destination.\"\n",
        ")\n",
        "\n",
        "hotel_tool = Tool(\n",
        "    name=\"Hotel Finder\",\n",
        "    func=find_hotels,\n",
        "    description=\"Finds hotels near a specified location.\"\n",
        ")\n",
        "\n",
        "# Initialize LangChain agent\n",
        "agent = initialize_agent([flight_tool, hotel_tool], llm, agent_type=AgentType.CONVERSATIONAL_REACT_DESCRIPTION)\n",
        "\n",
        "# Handle the query\n",
        "query = \"Find me flights to Paris and a hotel near the Eiffel Tower.\"\n",
        "response = agent.run(query)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnWZQ0p6cY9q"
      },
      "id": "gnWZQ0p6cY9q",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}